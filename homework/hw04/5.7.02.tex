\begin{problem}
  \probNum{5.7.2} Let ${Y_1,Y_2,\ldots,Y_n}$ be a random sample of size~$n$ from a normal pdf having~${\mu = 0}$.  Show that ${S^2 = \frac{1}{n} \sum_{i=1}^{n} Y_{i}^2}$ is a consistent estimator for ${\sigma^{2} = \text{Var}(Y)}$.
\end{problem}

It is easy to show $S^2$ is an unbiased estimate of $\sigma^2$ since:
\begin{align}
  \expect{S^2} &= \expect{\frac{1}{n} \sum_{i=1}^{n} Y_{i}^{2}} \\
               &= \frac{1}{n} \sum_{i=1}^{n} \expect{Y_{i}^{2}} \\
               &= \expect{Y^2} \\
               &= \sigma^{2} \text{.}
\end{align}

By Chebyshev's Inequality,
\begin{equation}\label{eq:HW04:P05:Chebyshev}
  \Pr\sbrack{\abs{S^2 - \sigma^2} \geq \epsilon} \leq \frac{\var{\sigma^2}}{n\epsilon^2}\text{.}
\end{equation}

To prove consistency, it is sufficient to show $\var{\sigma^2}$~is finite. The fourth moment of $\var{\sigma^2}$ for a zero-mean Gaussian can be found online (e.g.,~Wikipedia) and is known to be finite meaning the probability in Eq.~\eqref{eq:HW04:P05:Chebyshev} converges to~0.
